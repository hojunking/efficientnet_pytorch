{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7b477f4",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2a55991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from glob import glob\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "import cv2\n",
    "from skimage import io\n",
    "from torch import nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re, magic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from  torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import sklearn\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import cv2\n",
    "#import pydicom\n",
    "import timm #from efficientnet_pytorch import EfficientNet\n",
    "from scipy.ndimage import zoom\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#vit\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e7a61d-bf78-42e6-a46e-08295e35dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "#from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0, 1' #본인이 사용하고 싶은 GPU 넘버를 써주면 됨\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '53097'         # 좀 큰 숫자로 맞추면 됨 작은 숫자는 에러발생!\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# init!\n",
    "torch.distributed.init_process_group(backend='nccl', init_method=\"env://\", rank =0, world_size=1)  # rank should be 0 ~ world_size-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08b7b520",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 0,\n",
    "    'model': 'tf_efficientnet_b3_ns',\n",
    "    'img_size': 300,\n",
    "    'epochs': 50,\n",
    "    'train_bs': 16,\n",
    "    'valid_bs': 16,\n",
    "    'T_0': 10,\n",
    "    'lr': 1e-4,\n",
    "    'min_lr': 1e-6,\n",
    "    'weight_decay':1e-5,\n",
    "    'num_workers': 0,\n",
    "    'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "    'verbose_step': 1,\n",
    "    'device': 'cuda:0'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf4d237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    #print(im_rgb)\n",
    "    return im_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bb8a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColonDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, df, data_root, transforms=None):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transforms = transforms\n",
    "        self.data_root = data_root\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # get labels\n",
    "        if self.output_label:\n",
    "            target = self.df.iloc[index]['label']\n",
    "          \n",
    "        path = \"{}/{}\".format(self.data_root, self.df.iloc[index]['image_id'])\n",
    "        #path = \"{}/{}\".format(self.data_root[index], self.df.iloc[index]['image_id'])\n",
    "        img  = get_img(path)\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "            \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4b5efe-536c-4d22-8918-63a5642625e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43c6ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize, SmallestMaxSize\n",
    ")\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def get_inference_transforms():\n",
    "    return Compose([\n",
    "            CenterCrop(always_apply=True,p=1.0, height=CFG['img_size'], width=CFG['img_size']),\n",
    "            RandomResizedCrop(\n",
    "            height=CFG['img_size'], \n",
    "            width=CFG['img_size'], \n",
    "            scale=(0.60, 0.64),\n",
    "            ratio=(0.90, 1.10),\n",
    "            always_apply=True\n",
    "            ),\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "#            VerticalFlip(p=0.5),\n",
    "#             HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "#             RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27db9516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96137820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColonImgClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_class=2, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained, num_classes=n_class)\n",
    "        try :\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, n_class)\n",
    "\n",
    "        except :\n",
    "            \n",
    "            try : \n",
    "                n_features = self.model.fc.in_features\n",
    "                self.model.fc = nn.Linear(n_features, n_class)\n",
    "            \n",
    "            except :\n",
    "                try:\n",
    "                    n_features = self.model.head.fc.in_channels\n",
    "                    self.model.head.fc = nn.Conv2d(n_features,n_class,kernel_size=(1, 1), stride=(1, 1))\n",
    "            \n",
    "                except:\n",
    "                    n_features = self.model.head.in_features\n",
    "                    self.model.head = nn.Linear(n_features, n_class)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13933652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_one_epoch(model, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    image_preds_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        \n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        print(image_preds_all)\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    print(f'final: {image_preds_all}')\n",
    "    return image_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b54d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e676eedb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seed_everything' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mefficientnet_lite0/20\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m_drop_efficientnet_lite0_28\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      5\u001b[0m      \u001b[38;5;66;03m# for training only, need nightly build pytorch\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mseed_everything\u001b[49m(CFG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      9\u001b[0m     test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m     10\u001b[0m     test_ds \u001b[38;5;241m=\u001b[39m ColonDataset(test, test_dir, transforms\u001b[38;5;241m=\u001b[39mget_valid_transforms(), output_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seed_everything' is not defined"
     ]
    }
   ],
   "source": [
    "test_dir = 'test_data/'\n",
    "#test_dir = test.dir.values\n",
    "model_dir = 'tf_efficientnet_b3_ns/tf_efficientnet_b3_ns_38'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "     # for training only, need nightly build pytorch\n",
    "\n",
    "    seed_everything(CFG['seed'])\n",
    "\n",
    "    #test = []\n",
    "    test_ds = ColonDataset(test, test_dir, transforms=get_inference_transforms())\n",
    "\n",
    "\n",
    "    tst_loader = torch.utils.data.DataLoader(\n",
    "        test_ds, \n",
    "        batch_size=CFG['valid_bs'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    device = torch.device(CFG['device'])\n",
    "    model = ColonImgClassifier(CFG['model'], 134).to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    \n",
    "    model.to(device)\n",
    "    model = DDP(model)\n",
    "    \n",
    "    tst_preds = []\n",
    "\n",
    "    model.load_state_dict(torch.load(model_dir))\n",
    "\n",
    "    with torch.no_grad():\n",
    "            tst_preds += [inference_one_epoch(model, tst_loader, device)]\n",
    "\n",
    "\n",
    "    #tst_preds = inference_one_epoch(model, tst_loader, device)\n",
    "    tst_preds = np.mean(tst_preds, axis=0) \n",
    "    print(f'mean of tst_preds = {tst_preds}')\n",
    "    #print('test loss = {:.5f}'.format(log_loss(valid_.label.values, val_preds)))\n",
    "    #print('test accuracy = {:.5f}'.format((valid_.label.values==np.argmax(val_preds, axis=1)).mean()))\n",
    "\n",
    "    #  del model, tst_loader\n",
    "    # torch.cuda.empty_cache()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60f9bf8b-8afe-4f80-9e53-b2f690b96198",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tst_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtst_preds\u001b[49m\u001b[38;5;241m.\u001b[39msorted(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tst_preds' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2df69d0",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b7ab87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "447a97d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "# test['label'] = test['image_id'].apply(lambda x : 0 if 'cancer' in x else 1)\n",
    "test['pred'] = np.argmax(tst_preds, axis=1)\n",
    "#test['pred'] = tst_preds\n",
    "test['confidence score'] =np.max(tst_preds, axis=1)\n",
    "#test_acc = np.sum(test.label == test.pred) / len(test)\n",
    "#test_matrix = confusion_matrix(test['label'], test['pred'])\n",
    "#print(round(test_acc, 5))\n",
    "#print(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db57b665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e572e130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
