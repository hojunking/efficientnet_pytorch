{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69b5700-ef0f-4890-a29b-674451e154f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "from torch import nn\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import sklearn\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import timm\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9814f194-198b-4d5d-b3ea-3bf4bd119f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'model': 'tf_efficientnet_b4_ns',\n",
    "    'img_size': 380,\n",
    "    'bs': 16,\n",
    "    'seed': 0,\n",
    "    'device': 'cuda:0',\n",
    "    'img_dir': 'test_data/',\n",
    "    'num_workers': 0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2399a070-f937-487f-ac62-ab2554b703e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m#print(im_rgb)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m im_rgb\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mget_transformed_img\u001b[39;00m(\u001b[43mDataset\u001b[49m):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28mself\u001b[39m, df, data_root, transforms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    #print(im_rgb)\n",
    "    return im_rgb\n",
    "    \n",
    "    \n",
    "class get_transformed_img(Dataset):\n",
    "    def __init__(\n",
    "        self, df, data_root, transforms=None):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transforms = transforms\n",
    "        self.data_root = data_root\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "          \n",
    "        path = \"{}/{}\".format(self.data_root, self.df.iloc[index]['image_id'])\n",
    "        #path = \"{}/{}\".format(self.data_root[index], self.df.iloc[index]['image_id'])\n",
    "        img  = get_img(path)\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "            \n",
    "        return img    \n",
    "    \n",
    "\n",
    "def get_inference_transforms():\n",
    "     return A.Compose([\n",
    "#            A.Resize(CFG['img_size'], CFG['img_size']),\n",
    "#            A.CenterCrop(always_apply=True,p=1.0, height=CFG['img_size'], width=CFG['img_size']),\n",
    "            A.RandomResizedCrop(\n",
    "            height=CFG['img_size'], \n",
    "            width=CFG['img_size'], \n",
    "            scale=(0.90, 0.99),\n",
    "            ratio=(0.90, 1.10),\n",
    "            always_apply=True\n",
    "            ),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec94643-36c0-4a1e-9909-533dda5ec10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### get model\n",
    "class ColonImgClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_class=2, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained, num_classes=n_class)\n",
    "        try :\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, n_class)\n",
    "\n",
    "        except :\n",
    "            \n",
    "            try : \n",
    "                n_features = self.model.fc.in_features\n",
    "                self.model.fc = nn.Linear(n_features, n_class)\n",
    "            \n",
    "            except :\n",
    "                try:\n",
    "                    n_features = self.model.head.fc.in_channels\n",
    "                    self.model.head.fc = nn.Conv2d(n_features,n_class,kernel_size=(1, 1), stride=(1, 1))\n",
    "            \n",
    "                except:\n",
    "                    n_features = self.model.head.in_features\n",
    "                    self.model.head = nn.Linear(n_features, n_class)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "########################## inference #############################\n",
    "##########################           #############################\n",
    "def inference(model, data_loader, device):\n",
    "    model.eval()\n",
    "    image_preds_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "\n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74adc1b-1d6b-4275-af29-d4ee83bb727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## main ##################################\n",
    "##########################      ##################################\n",
    "#model_dir = 'tf_efficientnet_b4_ns_ALL/tf_efficientnet_b4_ns_6'\n",
    "#model_dir = 'models/1214'\n",
    "\n",
    "warnings.filterwarnings(action='ignore') \n",
    "###### Multi GPU init\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0, 1' #본인이 사용하고 싶은 GPU 넘버를 써주면 됨\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '53097'         # 좀 큰 숫자로 맞추면 됨 작은 숫자는 에러발생!\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# init!\n",
    "torch.distributed.init_process_group(backend='nccl', init_method=\"env://\", rank =0, world_size=1)  # rank should be 0 ~ world_size-1\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    # arguments = sys.argv\n",
    "    # del arguments[0]\n",
    "    \n",
    "    #img_name = arguments\n",
    "    img_name = ['모닝_2017.jpg',\n",
    " 'K3_2021.jpg',\n",
    " 'K9_2020.jpg',\n",
    " '아반떼_2017.jpg',\n",
    " 'EQ900_2018.jpg',\n",
    " '그랜저_2019.jpg',\n",
    " 'G70_2017.jpg',\n",
    " '니로_2017.jpg',\n",
    " '아반떼_2019.01.jpg',\n",
    " '카니발_2019.jpg',\n",
    " 'K3_2017.jpg',\n",
    " 'K3_2020.jpg',\n",
    " 'K9_2019.jpg',\n",
    " 'K5_2017.jpg',\n",
    " '스토닉_2018.jpg',\n",
    " 'K5_2019.jpg',\n",
    " '투싼_2018.jpg',\n",
    " '아반떼_2019.jpg',\n",
    " '셀토스_2021.jpg',\n",
    " '레이_2020.jpg',\n",
    " '팰리세이드_2021.jpg',\n",
    " '싼타페_2018.jpg',\n",
    " 'G70_2019.jpg',\n",
    " '스타렉스_2018.jpg',\n",
    " '스팅어_2019.jpg',\n",
    " '아반떼_2021.jpg',\n",
    " '쏘나타_2018.jpg',\n",
    " '스타렉스_2019.jpg',\n",
    " 'G80_2021.jpg',\n",
    " '싼타페_2019.jpg',\n",
    " 'K7_2018.jpg',\n",
    " '쏘렌토_2017.jpg',\n",
    " '쏘나타_2017.jpg',\n",
    " '모닝_2018.jpg',\n",
    " '그랜저.2018.jpg',\n",
    " '투싼_2020.jpg',\n",
    " '쏘나타_2021.jpg',\n",
    " '그랜저_2017.jpg',\n",
    " '니로_2018.jpg',\n",
    " '포터2_2017.jpg']\n",
    "    #print(img_name)\n",
    "    img_dir = CFG['img_dir']\n",
    "    #path = img_dir + img_name\n",
    "    \n",
    "    \n",
    "    \n",
    "    infer = pd.DataFrame(columns = ['image_id'])\n",
    "    infer['image_id'] = img_name\n",
    "    \n",
    "    ############## for test accuracy #####################\n",
    "    infer['label'] = [i.replace('_','/').split('.',1)[0] for i in img_name]\n",
    "    \n",
    "    \n",
    "    ################## get img ###########################\n",
    "    pred_ds = get_transformed_img(infer, img_dir, transforms=get_inference_transforms())\n",
    "    pred_loader = torch.utils.data.DataLoader(\n",
    "        pred_ds, \n",
    "        batch_size=CFG['bs'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    ################## model init ########################\n",
    "    device = torch.device(CFG['device'])\n",
    "    model = ColonImgClassifier(CFG['model'], 95).to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    \n",
    "    model.to(device)\n",
    "    model = DDP(model)\n",
    "    \n",
    "    \n",
    "    ################## get inference #####################\n",
    "    predictions = []\n",
    "    model.load_state_dict(torch.load(model_dir))\n",
    "    with torch.no_grad():\n",
    "        predictions += [inference(model, pred_loader, device)]\n",
    "\n",
    "\n",
    "    #tst_preds = inference_one_epoch(model, tst_loader, device)\n",
    "    predictions = np.mean(predictions, axis=0) \n",
    "    #print(f'mean of tst_preds = {predictions}')\n",
    "    \n",
    "    # top_3 = predictions[0].argsort()[-3:][::-1]\n",
    "    # print(f'top_3 : {top_3}')\n",
    "    \n",
    "\n",
    "\n",
    "# encoded_labels = ['BMW/3시리즈/2017', 'BMW/3시리즈/2018', 'BMW/5시리즈/2017', 'BMW/5시리즈/2018',\n",
    "#        '기아/K3/2017', '기아/K3/2018', '기아/K3/2019', '기아/K3/2020',\n",
    "#        '기아/K3/2021', '기아/K5/2017', '기아/K5/2018', '기아/K5/2019',\n",
    "#        '기아/K5/2020', '기아/K7/2017', '기아/K7/2018', '기아/K7/2019',\n",
    "#        '기아/K7/2020', '기아/K9/2019', '기아/K9/2020', '기아/K9/2021',\n",
    "#        '기아/니로/2017', '기아/니로/2018', '기아/니로/2019', '기아/니로/2020',\n",
    "#        '기아/레이/2017', '기아/레이/2018', '기아/레이/2019', '기아/레이/2020',\n",
    "#        '기아/모닝/2017', '기아/모닝/2018', '기아/모닝/2019', '기아/모닝/2020',\n",
    "#        '기아/모닝/2021', '기아/모하비/2017', '기아/모하비/2018', '기아/봉고3/2017',\n",
    "#        '기아/셀토스/2021', '기아/스토닉/2018', '기아/스토닉/2019', '기아/스팅어/2018',\n",
    "#        '기아/스팅어/2019', '기아/스팅어/2020', '기아/스포티지/2017', '기아/스포티지/2018',\n",
    "#        '기아/스포티지/2019', '기아/쏘렌토/2017', '기아/쏘렌토/2018', '기아/쏘렌토/2019',\n",
    "#        '기아/쏘렌토/2020', '기아/쏘렌토/2021', '기아/카니발/2017', '기아/카니발/2018',\n",
    "#        '기아/카니발/2019', '기아/카니발/2020', '랜드로버/레인지로버/2017', '르노삼성/QM3/2017',\n",
    "#        '르노삼성/QM6/2017', '르노삼성/QM6/2018', '르노삼성/QM6/2019', '르노삼성/QM6/2020',\n",
    "#        '르노삼성/SM3/2018', '르노삼성/SM5/2017', '르노삼성/SM6/2017', '르노삼성/SM6/2018',\n",
    "#        '르노삼성/SM6/2019', '벤츠/C-Class/2017', '벤츠/E-Class/2017',\n",
    "#        '벤츠/E-Class/2018', '벤츠/E-Class/2019', '벤츠/E-Class/2020',\n",
    "#        '벤츠/S-Class/2017', '벤츠/S-Class/2018', '쉐보레/말리부/2017',\n",
    "#        '쉐보레/말리부/2018', '쉐보레/스파크/2017', '쉐보레/스파크/2018', '쉐보레/스파크/2019',\n",
    "#        '쉐보레/스파크/2020', '쉐보레/올란도/2018', '쉐보레/크루즈/2017', '쌍용/G4렉스턴/2018',\n",
    "#        '쌍용/렉스턴스포츠/2019', '쌍용/티볼리/2017', '쌍용/티볼리/2018', '쌍용/티볼리/2019',\n",
    "#        '아우디/A6/2017', '제네시스/EQ900/2017', '제네시스/EQ900/2018',\n",
    "#        '제네시스/G70/2017', '제네시스/G70/2018', '제네시스/G70/2019', '제네시스/G80/2017',\n",
    "#        '제네시스/G80/2018', '제네시스/G80/2019', '제네시스/G80/2021', '제네시스/G90/2019',\n",
    "#        '포드/익스플로러/2017', '포드/익스플로러/2018', '폭스바겐/티구안/2017', '현대/그랜저/2017',\n",
    "#        '현대/그랜저/2018', '현대/그랜저/2019', '현대/그랜저/2020', '현대/그랜저/2021',\n",
    "#        '현대/베뉴/2020', '현대/스타렉스/2017', '현대/스타렉스/2018', '현대/스타렉스/2019',\n",
    "#        '현대/스타렉스/2020', '현대/싼타페/2017', '현대/싼타페/2018', '현대/싼타페/2019',\n",
    "#        '현대/싼타페/2020', '현대/쏘나타/2017', '현대/쏘나타/2018', '현대/쏘나타/2019',\n",
    "#        '현대/쏘나타/2020', '현대/쏘나타/2021', '현대/아반떼/2017', '현대/아반떼/2018',\n",
    "#        '현대/아반떼/2019', '현대/아반떼/2020', '현대/아반떼/2021', '현대/코나/2018',\n",
    "#        '현대/코나/2019', '현대/코나/2020', '현대/투싼/2017', '현대/투싼/2018',\n",
    "#        '현대/투싼/2019', '현대/투싼/2020', '현대/팰리세이드/2019', '현대/팰리세이드/2020',\n",
    "#        '현대/팰리세이드/2021', '현대/포터2/2017']\n",
    "\n",
    "encoded_labels = ['기아/K3/2017', '기아/K3/2018', '기아/K3/2019', '기아/K3/2020',\n",
    "       '기아/K3/2021', '기아/K5/2017', '기아/K5/2018', '기아/K5/2019',\n",
    "       '기아/K5/2020', '기아/K7/2017', '기아/K7/2018', '기아/K7/2019',\n",
    "       '기아/K7/2020', '기아/K9/2019', '기아/K9/2020', '기아/K9/2021',\n",
    "       '기아/니로/2017', '기아/니로/2018', '기아/니로/2019', '기아/니로/2020',\n",
    "       '기아/레이/2017', '기아/레이/2018', '기아/레이/2019', '기아/레이/2020',\n",
    "       '기아/모닝/2017', '기아/모닝/2018', '기아/모닝/2019', '기아/모닝/2020',\n",
    "       '기아/모닝/2021', '기아/모하비/2017', '기아/모하비/2018', '기아/봉고3/2017',\n",
    "       '기아/셀토스/2021', '기아/스토닉/2018', '기아/스토닉/2019', '기아/스팅어/2018',\n",
    "       '기아/스팅어/2019', '기아/스팅어/2020', '기아/스포티지/2017', '기아/스포티지/2018',\n",
    "       '기아/스포티지/2019', '기아/쏘렌토/2017', '기아/쏘렌토/2018', '기아/쏘렌토/2019',\n",
    "       '기아/쏘렌토/2020', '기아/쏘렌토/2021', '기아/카니발/2017', '기아/카니발/2018',\n",
    "       '기아/카니발/2019', '기아/카니발/2020', '제네시스/EQ900/2017', '제네시스/EQ900/2018',\n",
    "       '제네시스/G70/2017', '제네시스/G70/2018', '제네시스/G70/2019', '제네시스/G80/2017',\n",
    "       '제네시스/G80/2018', '제네시스/G80/2019', '제네시스/G80/2021', '제네시스/G90/2019',\n",
    "       '현대/그랜저/2017', '현대/그랜저/2018', '현대/그랜저/2019', '현대/그랜저/2020',\n",
    "       '현대/그랜저/2021', '현대/베뉴/2020', '현대/스타렉스/2017', '현대/스타렉스/2018',\n",
    "       '현대/스타렉스/2019', '현대/스타렉스/2020', '현대/싼타페/2017', '현대/싼타페/2018',\n",
    "       '현대/싼타페/2019', '현대/싼타페/2020', '현대/쏘나타/2017', '현대/쏘나타/2018',\n",
    "       '현대/쏘나타/2019', '현대/쏘나타/2020', '현대/쏘나타/2021', '현대/아반떼/2017',\n",
    "       '현대/아반떼/2018', '현대/아반떼/2019', '현대/아반떼/2020', '현대/아반떼/2021',\n",
    "       '현대/코나/2018', '현대/코나/2019', '현대/코나/2020', '현대/투싼/2017',\n",
    "       '현대/투싼/2018', '현대/투싼/2019', '현대/투싼/2020', '현대/팰리세이드/2019',\n",
    "       '현대/팰리세이드/2020', '현대/팰리세이드/2021', '현대/포터2/2017']\n",
    "\n",
    "# 라벨인코더 선언 및 Fitting\n",
    "le = LabelEncoder()\n",
    "le.fit(encoded_labels)\n",
    "\n",
    "pred_count = 0\n",
    "\n",
    "for i,pre in enumerate(predictions):\n",
    "    top_3 = pre.argsort()[-3:][::-1]\n",
    "    pred = le.inverse_transform(top_3)\n",
    "    pred = [p.split('/',1)[1] for p in pred]\n",
    "    \n",
    "    if any (infer['label'][i].split('/',1) == pre_val.split('/',1) for pre_val in pred):\n",
    "        pred_count = pred_count +1\n",
    "    label = infer['label'][i]\n",
    "    #print(f'label:[{label}]  top3: {pred}')\n",
    "\n",
    "print(f'accuracy = {pred_count / len(infer)}')\n",
    "# top_3 = pre.argsort()[-3:][::-1]\n",
    "#     print(len(top_3))\n",
    "#     print(len(infer))\n",
    "#     infer['pred'] = le.inverse_transform(top_3)\n",
    "    \n",
    "#     infer['pred'] = [t_pred.split('/',1)[1] for t_pred in infer['pred']]\n",
    "#     print(infer['pred'])\n",
    "    \n",
    "#     print(f'top3:{infer.label} : {infer.pred}')\n",
    "#     print(f'accuracy = {np.sum(infer.label == infer.pred) / len(infer)}')\n",
    "\n",
    "\n",
    "# prediction = le.inverse_transform(top_3)\n",
    "# print(prediction)\n",
    "\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "# print(torch.cuda.memory_allocated())\n",
    "# print(torch.cuda.memory_reserved())\n",
    "\n",
    "\n",
    "dist.destroy_process_group()\n",
    "#bashCommand = \"nvidia-smi | grep 'python' | awk '{ print $5 }' | xargs -n1 kill -9\"\n",
    "#os.system(bashCommand)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
